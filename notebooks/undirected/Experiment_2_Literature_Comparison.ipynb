{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('anonymigraph').setLevel(logging.INFO)\n",
    "logging.getLogger('anonymigraph.metrics').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anonymigraph.metrics.evaluator import Evaluator\n",
    "from anonymigraph.metrics.utility.structural.privacy_metrics import PercentageKDegreeAnonMetric\n",
    "\n",
    "from anonymigraph.metrics.utility.structural import (\n",
    "    DegreeCentralityMetric,\n",
    "    EigenvectorMetric,\n",
    "    PageRankMetric,\n",
    "    ClosenessCentralityMetric,\n",
    "    LocalClusteringCoefficientMetric,\n",
    "    WLColorMetric,\n",
    "\n",
    "    ConnectedComponentsMetric,\n",
    "    NumberOfEdgesMetric,\n",
    "    NumberOfNodesMetric,\n",
    "    NumberOfTrianglesMetric,\n",
    "    MeanDegreeMetric,\n",
    "    MaxDegreeMetric,\n",
    "    MedianDegreeMetric,\n",
    "    AverageClusteringCoefficientMetric,\n",
    "    TransitivityMetric,\n",
    "\n",
    "    EdgeJaccardMetric,\n",
    "    KatzCentralityMetric,\n",
    "\n",
    ")\n",
    "\n",
    "from anonymigraph.anonymization import (\n",
    "    KDegreeAnonymizer,\n",
    "    RandomEdgeAddDelAnonymizer,\n",
    "    ConfigurationModelAnonymizer,\n",
    "    NestModelAnonymizer,\n",
    "    PygmalionModelAnonymizer,\n",
    "    PrivateColorAnonymizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def get_latex_table(data, precision=5):\n",
    "    \"\"\"Helper function to get the latex code for the table\"\"\"\n",
    "\n",
    "    G_values = {}\n",
    "    cleaned_data = {}\n",
    "    for key, metrics in data.items():\n",
    "        new_entry = {}\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            if isinstance(metric_value, dict):\n",
    "                G_values[metric_name] = metric_value[\"G\"]\n",
    "                new_entry[metric_name] = metric_value[\"Ga\"]\n",
    "            else:\n",
    "                new_entry[metric_name] = metric_value\n",
    "\n",
    "        cleaned_data[key] = new_entry\n",
    "\n",
    "    for metric in list(cleaned_data.values())[0].keys():\n",
    "        if metric not in G_values:\n",
    "            G_values[metric] = None\n",
    "\n",
    "    # Categories\n",
    "    utility_scalar_metrics = ['|V|', '|E|', 'C']\n",
    "    utility_distributions_metrics = ['Deg.','Katz','Ev.','CC','LCC']\n",
    "    all_metrics = list(list(cleaned_data.values())[0].keys())\n",
    "    privacy_metrics = [m for m in all_metrics\n",
    "                    if m not in utility_scalar_metrics and m not in utility_distributions_metrics]\n",
    "\n",
    "    df = pd.DataFrame(cleaned_data).T\n",
    "    ordered_metrics = utility_scalar_metrics + utility_distributions_metrics + privacy_metrics\n",
    "    df = df[ordered_metrics]\n",
    "\n",
    "    df_str = df.copy()\n",
    "    best_indices = {}\n",
    "    for col in df.columns:\n",
    "        best_indices[col] = df[col].nsmallest(3).index\n",
    "    for c_idx, col in enumerate(df_str.columns):\n",
    "        # Decide precision based on column:\n",
    "        if c_idx in [0, 1]:\n",
    "            df_str[col] = df_str[col].apply(lambda x: f\"{int(x)}\")\n",
    "        elif c_idx in list(range(2,8)):\n",
    "            df_str[col] = df_str[col].apply(lambda x: f\"{x:.{precision}f}\")\n",
    "        else:\n",
    "            df_str[col] = df_str[col].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "        if c_idx in list(range(3,10)):\n",
    "            for idx in best_indices[col]:\n",
    "                df_str.loc[idx, col] = f\"\\\\textbf{{{df_str.loc[idx, col]}}}\"\n",
    "\n",
    "    df_str.loc[len(df)] = G_values\n",
    "    latex_str = df_str.to_latex(index=True,\n",
    "                                caption=\"\",\n",
    "                                label=\"tab:\",\n",
    "                                bold_rows=True,\n",
    "                                column_format=\"l\" + \"c\"*(df.shape[1]),\n",
    "                                formatters=[str] * len(df.columns)\n",
    "                            )\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "def get_statics_of_samples(sample_data):\n",
    "    \"\"\"Helper function which aggregates sample runs to mean and stds.\"\"\"\n",
    "    averages = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for entry in sample_data:\n",
    "        for method, metrics in entry.items():\n",
    "            for metric, value in metrics.items():\n",
    "                if isinstance(value, dict):\n",
    "                    averages[method][metric].append(value['Ga'])\n",
    "                else:\n",
    "                    averages[method][metric].append(value)\n",
    "\n",
    "    means = {\n",
    "        method: {\n",
    "            metric: float(np.mean(vals)) for metric, vals in metrics.items()\n",
    "        }\n",
    "        for method, metrics in averages.items()\n",
    "    }\n",
    "\n",
    "    rel_stds = {\n",
    "        method: {\n",
    "            metric: float(np.std(vals)/np.mean(vals)) for metric, vals in metrics.items()\n",
    "        }\n",
    "        for method, metrics in averages.items()\n",
    "    }\n",
    "\n",
    "    return means, rel_stds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polbooks (|V| = 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.sparse.linalg import eigs\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists('polbooks.gml'):\n",
    "    urllib.request.urlretrieve('https://networkdata.ics.uci.edu/data/polbooks/polbooks.gml', 'polbooks.gml')\n",
    "\n",
    "G = nx.read_gml('polbooks.gml')\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "eigenvalues, _ = eigs(nx.adjacency_matrix(G).astype(np.float64), k=1, which='LM')\n",
    "max_alpha = 1 / np.abs(eigenvalues).max()\n",
    "\n",
    "alpha=0.5*max_alpha\n",
    "beta=1\n",
    "print(G)\n",
    "print(\"Alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polbooks_samples_data = []\n",
    "for seed in range(42, 42+4): # 4 samples with different seeds\n",
    "    # METRICS\n",
    "    metrics = {\n",
    "        # Important\n",
    "        # Graph Level\n",
    "        \"|V|\": NumberOfNodesMetric(),\n",
    "        \"|E|\": NumberOfEdgesMetric(),\n",
    "        \"C\": AverageClusteringCoefficientMetric(),\n",
    "        #\"|Î”|\": NumberOfTrianglesMetric(),\n",
    "        #\"Transitivity\": TransitivityMetric(),\n",
    "\n",
    "        # Node Level\n",
    "        \"Deg.\": DegreeCentralityMetric(),\n",
    "        \"Katz\": KatzCentralityMetric(alpha=alpha),\n",
    "        \"Ev.\": EigenvectorMetric(),\n",
    "        \"LCC\": LocalClusteringCoefficientMetric(),\n",
    "        \"CC\": ClosenessCentralityMetric(),\n",
    "        #\"TVD WL Colors d=2\": WLColorMetric(depth=2),\n",
    "\n",
    "        # Graph Level\n",
    "        #\"|CC|\": ConnectedComponentsMetric(),\n",
    "        #\"Median Deg.\": MedianDegreeMetric(),\n",
    "        #\"Avg. Deg.\": MeanDegreeMetric(),\n",
    "        #\"Max Deg.\": MaxDegreeMetric(),\n",
    "        #\"PageRank\":\tPageRankMetric(),\n",
    "\n",
    "        r\"\\(\\vert E \\cap E'\\vert\\)\": EdgeJaccardMetric(),\n",
    "        r\"\\% 4-degree Anon\": PercentageKDegreeAnonMetric(k=4),\n",
    "        r\"\\% 16-degree Anon\": PercentageKDegreeAnonMetric(k=16),\n",
    "    }\n",
    "\n",
    "    methods = {}\n",
    "    #methods[\"Configuration Model\"] = ConfigurationModelAnonymizer()\n",
    "\n",
    "    methods[r\"NeSt \\(d=1\\)\"] = NestModelAnonymizer(depth=1, r=10)\n",
    "    methods[r\"NeSt \\(d=2\\)\"] = NestModelAnonymizer(depth=2, r=10)\n",
    "\n",
    "    #methods[\"PrivateColor(w=1e1)\"] = PrivateColorAnonymizer(w=1e1, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-2}\\)\"] = PrivateColorAnonymizer(w=1e-2, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-3}\\)\"] = PrivateColorAnonymizer(w=1e-3, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-4}\\)\"] = PrivateColorAnonymizer(w=1e-4, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "\n",
    "    methods[r\"16\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(16/100*G.number_of_edges()))\n",
    "    #methods[f\"{8}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(8/100*G.number_of_edges()))\n",
    "    methods[r\"4\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(4/100*G.number_of_edges()))\n",
    "    #methods[f\"{2}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(2/100*G.number_of_edges()))\n",
    "    methods[r\"1\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(1/100*G.number_of_edges()))\n",
    "\n",
    "    methods[r\"64-Degree Anonymity\"] = KDegreeAnonymizer(k=64)\n",
    "    #methods[f\"{32}-Degree Anonymity\"] = KDegreeAnonymizer(k=32)\n",
    "    methods[r\"16-Degree Anonymity\"] = KDegreeAnonymizer(k=16)\n",
    "    #methods[f\"{8}-Degree Anonymity\"] = KDegreeAnonymizer(k=8)\n",
    "    methods[r\"4-Degree Anonymity\"] = KDegreeAnonymizer(k=4)\n",
    "    #methods[f\"{2}-Degree Anonymity\"] = KDegreeAnonymizer(k=2)\n",
    "\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 1\\)\"] = PygmalionModelAnonymizer(eps = 1)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 100\\)\"] = PygmalionModelAnonymizer(eps = 100)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = \\infty\\)\"] = PygmalionModelAnonymizer(eps = 100_000_000)\n",
    "\n",
    "    evaluator = Evaluator(metrics, use_igraph=True)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        print(f\"Anonymizing with method {method_name}\")\n",
    "        Ga = method.anonymize(G, random_seed=seed)\n",
    "        print(f\"Evaluating method {method_name}\")\n",
    "        data[method_name] = evaluator.evaluate(G, Ga)\n",
    "\n",
    "    polbooks_samples_data.append(data)\n",
    "\n",
    "os.makedirs('cache', exist_ok=True)\n",
    "with open('cache/exp3_comp_polbooks_samples_data.pkl', 'wb') as f:\n",
    "    pickle.dump(polbooks_samples_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/exp3_comp_polbooks_samples_data.pkl', 'rb') as f:\n",
    "    polbooks_samples_data = pickle.load(f)\n",
    "\n",
    "means, rel_stds = get_statics_of_samples(polbooks_samples_data)\n",
    "print(get_latex_table(polbooks_samples_data[0]))\n",
    "print(get_latex_table(means))\n",
    "print(get_latex_table(rel_stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{NeSt \\(d=1\\)} & 105 & 441 & 0.15275 & \\textbf{0.00000} & 0.00182 & 0.01673 & 0.09551 & 0.33478 & 0.09 & \\textbf{0.74} & 0.21 \\\\\n",
    "\\textbf{NeSt \\(d=2\\)} & 105 & 441 & 0.26719 & \\textbf{0.00000} & \\textbf{0.00028} & 0.01853 & 0.07457 & 0.22034 & 0.56 & \\textbf{0.74} & 0.21 \\\\\n",
    "\\textbf{Eager \\(w=10^{-2}\\)} & 105 & 441 & 0.16057 & \\textbf{0.00000} & 0.00036 & 0.01825 & 0.09209 & 0.32696 & 0.18 & \\textbf{0.74} & 0.21 \\\\\n",
    "\\textbf{Eager \\(w=10^{-3}\\)} & 105 & 441 & 0.21006 & 0.00000 & \\textbf{0.00017} & 0.01822 & 0.08972 & 0.27746 & 0.35 & 0.74 & 0.21 \\\\\n",
    "\\textbf{Eager \\(w=10^{-4}\\)} & 105 & 441 & 0.36911 & 0.00000 & \\textbf{0.00002} & 0.01650 & 0.05881 & 0.11842 & 0.77 & 0.74 & 0.21 \\\\\n",
    "\\textbf{16\\% Edge Add/Del} & 105 & 441 & 0.30970 & 0.00609 & 0.00334 & 0.01655 & 0.05986 & 0.17782 & 0.73 & 0.81 & 0.22 \\\\\n",
    "\\textbf{4\\% Edge Add/Del} & 105 & 441 & 0.43467 & 0.00256 & 0.00138 & \\textbf{0.00566} & \\textbf{0.02893} & \\textbf{0.05286} & 0.93 & 0.76 & 0.30 \\\\\n",
    "\\textbf{1\\% Edge Add/Del} & 105 & 441 & 0.47648 & 0.00114 & 0.00067 & \\textbf{0.00998} & \\textbf{0.01200} & \\textbf{0.01182} & 0.98 & 0.75 & 0.26 \\\\\n",
    "\\textbf{64-Degree Anonymity} & 105 & 315 & 0.13381 & 0.03626 & 0.02002 & 0.06270 & \\textbf{0.02161} & 0.35372 & 0.45 & 1.00 & 1.00 \\\\\n",
    "\\textbf{16-Degree Anonymity} & 105 & 436 & 0.33699 & 0.00861 & 0.00293 & 0.01642 & 0.05555 & 0.15054 & 0.77 & 1.00 & 1.00 \\\\\n",
    "\\textbf{4-Degree Anonymity} & 105 & 439 & 0.44248 & 0.00147 & 0.00080 & \\textbf{0.01443} & 0.03475 & \\textbf{0.04505} & 0.93 & 1.00 & 0.21 \\\\\n",
    "\\textbf{Pygmalion \\(\\epsilon = 1\\)} & 185 & 700 & 0.03193 & 0.08780 & 0.07194 & 0.06814 & 0.09623 & 0.45559 & \\textbf{0.02} & 0.81 & 0.37 \\\\\n",
    "\\textbf{Pygmalion \\(\\epsilon = 100\\)} & 111 & 420 & 0.12614 & 0.01263 & 0.00346 & 0.01819 & 0.07022 & 0.36139 & \\textbf{0.03} & 0.76 & 0.35 \\\\\n",
    "\\textbf{Pygmalion \\(\\epsilon = \\infty\\)} & 105 & 415 & 0.13945 & 0.00476 & 0.00300 & 0.02131 & 0.08569 & 0.34807 & \\textbf{0.04} & 0.79 & 0.37 \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA-GrQc (|V| = 5242)\n",
    "collaboration network https://snap.stanford.edu/data/ca-GrQc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "import os\n",
    "from scipy.sparse.linalg import eigs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if not os.path.exists('ca-GrQc.txt.gz'):\n",
    "    urllib.request.urlretrieve('https://snap.stanford.edu/data/ca-GrQc.txt.gz', 'ca-GrQc.txt.gz')\n",
    "\n",
    "with gzip.open('ca-GrQc.txt.gz', 'rt') as f:\n",
    "    G = nx.read_edgelist(f)\n",
    "\n",
    "# relabel and remove self loops\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "G.remove_edges_from(nx.selfloop_edges(G)) # There are 12 self loops in the original graph\n",
    "\n",
    "eigenvalues, _ = eigs(nx.adjacency_matrix(G).astype(np.float64), k=1, which='LM')\n",
    "max_alpha = 1 / np.abs(eigenvalues).max()\n",
    "\n",
    "alpha=0.5*max_alpha\n",
    "beta=1\n",
    "print(G)\n",
    "print(\"Alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_samples_data = []\n",
    "for seed in range(55, 55+4): # 4 samples with different seeds\n",
    "    # METRICS\n",
    "    metrics = {\n",
    "        # Important\n",
    "        # Graph Level\n",
    "        \"|V|\": NumberOfNodesMetric(),\n",
    "        \"|E|\": NumberOfEdgesMetric(),\n",
    "        \"C\": AverageClusteringCoefficientMetric(),\n",
    "        #\"|Î”|\": NumberOfTrianglesMetric(),\n",
    "        #\"Transitivity\": TransitivityMetric(),\n",
    "\n",
    "        # Node Level\n",
    "        \"Deg.\": DegreeCentralityMetric(),\n",
    "        \"Katz\": KatzCentralityMetric(alpha=alpha),\n",
    "        \"Ev.\": EigenvectorMetric(),\n",
    "        \"LCC\": LocalClusteringCoefficientMetric(),\n",
    "        \"CC\": ClosenessCentralityMetric(),\n",
    "        #\"TVD WL Colors d=2\": WLColorMetric(depth=2),\n",
    "\n",
    "        # Graph Level\n",
    "        #\"|CC|\": ConnectedComponentsMetric(),\n",
    "        #\"Median Deg.\": MedianDegreeMetric(),\n",
    "        #\"Avg. Deg.\": MeanDegreeMetric(),\n",
    "        #\"Max Deg.\": MaxDegreeMetric(),\n",
    "        #\"PageRank\":\tPageRankMetric(),\n",
    "\n",
    "        r\"\\(\\vert E \\cap E'\\vert\\)\": EdgeJaccardMetric(),\n",
    "        r\"\\% 16-degree Anon\": PercentageKDegreeAnonMetric(k=16),\n",
    "        r\"\\% 64-degree Anon\": PercentageKDegreeAnonMetric(k=64),\n",
    "    }\n",
    "\n",
    "    methods = {}\n",
    "    #methods[\"Configuration Model\"] = ConfigurationModelAnonymizer()\n",
    "\n",
    "    methods[r\"NeSt \\(d=1\\)\"] = NestModelAnonymizer(depth=1, r=10)\n",
    "    methods[r\"NeSt \\(d=2\\)\"] = NestModelAnonymizer(depth=2, r=10)\n",
    "\n",
    "    #methods[\"PrivateColor(w=1e1)\"] = PrivateColorAnonymizer(w=1e1, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-2}\\)\"] = PrivateColorAnonymizer(w=1e-2, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-3}\\)\"] = PrivateColorAnonymizer(w=1e-3, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-4}\\)\"] = PrivateColorAnonymizer(w=1e-4, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "\n",
    "    methods[r\"16\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(16/100*G.number_of_edges()))\n",
    "    #methods[f\"{8}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(8/100*G.number_of_edges()))\n",
    "    methods[r\"4\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(4/100*G.number_of_edges()))\n",
    "    #methods[f\"{2}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(2/100*G.number_of_edges()))\n",
    "    methods[r\"1\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(1/100*G.number_of_edges()))\n",
    "\n",
    "    methods[r\"128-Degree Anonymity\"] = KDegreeAnonymizer(k=128)\n",
    "    methods[r\"64-Degree Anonymity\"] = KDegreeAnonymizer(k=64)\n",
    "    #methods[f\"{32}-Degree Anonymity\"] = KDegreeAnonymizer(k=32)\n",
    "    methods[r\"16-Degree Anonymity\"] = KDegreeAnonymizer(k=16)\n",
    "    #methods[f\"{8}-Degree Anonymity\"] = KDegreeAnonymizer(k=8)\n",
    "    #methods[f\"{2}-Degree Anonymity\"] = KDegreeAnonymizer(k=2)\n",
    "\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 1\\)\"] = PygmalionModelAnonymizer(eps = 1)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 100\\)\"] = PygmalionModelAnonymizer(eps = 100)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = \\infty\\)\"] = PygmalionModelAnonymizer(eps = 100_000_000)\n",
    "\n",
    "    evaluator = Evaluator(metrics, use_igraph=True)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        print(f\"Anonymizing with method {method_name}\")\n",
    "        Ga = method.anonymize(G, random_seed=seed)\n",
    "        print(f\"Evaluating method {method_name}\")\n",
    "        data[method_name] = evaluator.evaluate(G, Ga)\n",
    "\n",
    "    ca_samples_data.append(data)\n",
    "\n",
    "os.makedirs('cache', exist_ok=True)\n",
    "with open('cache/exp3_comp_ca_samples_data.pkl', 'wb') as f:\n",
    "    pickle.dump(ca_samples_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/exp3_comp_ca_samples_data.pkl', 'rb') as f:\n",
    "    ca_samples_data = pickle.load(f)\n",
    "\n",
    "print(len(ca_samples_data))\n",
    "means, rel_stds = get_statics_of_samples(ca_samples_data)\n",
    "print(get_latex_table(ca_samples_data[0]))\n",
    "print(get_latex_table(means, precision=7))\n",
    "print(get_latex_table(rel_stds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron (|V| = 36692)\n",
    "Enron email communication network https://snap.stanford.edu/data/email-Enron.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import networkx as nx\n",
    "import urllib.request\n",
    "import os\n",
    "from scipy.sparse.linalg import eigs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if not os.path.exists('email-Enron.txt.gz'):\n",
    "    urllib.request.urlretrieve('https://snap.stanford.edu/data/email-Enron.txt.gz', 'email-Enron.txt.gz')\n",
    "\n",
    "with gzip.open('email-Enron.txt.gz', 'rt') as f:\n",
    "    G = nx.read_edgelist(f)\n",
    "\n",
    "# relabel and remove self loops\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "eigenvalues, _ = eigs(nx.adjacency_matrix(G).astype(np.float64), k=1, which='LM')\n",
    "max_alpha = 1 / np.abs(eigenvalues).max()\n",
    "\n",
    "alpha=0.5*max_alpha\n",
    "beta=1\n",
    "print(G)\n",
    "print(\"Alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(100_000) # for k-degree anon technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_samples_data = []\n",
    "for seed in range(42, 42+4): # 4 samples with different seeds\n",
    "    # METRICS\n",
    "    metrics = {\n",
    "        # Important\n",
    "        # Graph Level\n",
    "        \"|V|\": NumberOfNodesMetric(),\n",
    "        \"|E|\": NumberOfEdgesMetric(),\n",
    "        \"C\": AverageClusteringCoefficientMetric(),\n",
    "        #\"|Î”|\": NumberOfTrianglesMetric(),\n",
    "        #\"Transitivity\": TransitivityMetric(),\n",
    "\n",
    "        # Node Level\n",
    "        \"Deg.\": DegreeCentralityMetric(),\n",
    "        \"Katz\": KatzCentralityMetric(alpha=alpha),\n",
    "        \"Ev.\": EigenvectorMetric(),\n",
    "        \"LCC\": LocalClusteringCoefficientMetric(),\n",
    "        \"CC\": ClosenessCentralityMetric(),\n",
    "        #\"TVD WL Colors d=2\": WLColorMetric(depth=2),\n",
    "\n",
    "        # Graph Level\n",
    "        #\"|CC|\": ConnectedComponentsMetric(),\n",
    "        #\"Median Deg.\": MedianDegreeMetric(),\n",
    "        #\"Avg. Deg.\": MeanDegreeMetric(),\n",
    "        #\"Max Deg.\": MaxDegreeMetric(),\n",
    "        #\"PageRank\":\tPageRankMetric(),\n",
    "\n",
    "        r\"\\(\\vert E \\cap E'\\vert\\)\": EdgeJaccardMetric(),\n",
    "        r\"\\% 16-degree Anon\": PercentageKDegreeAnonMetric(k=16),\n",
    "        r\"\\% 64-degree Anon\": PercentageKDegreeAnonMetric(k=64),\n",
    "    }\n",
    "\n",
    "    methods = {}\n",
    "    #methods[\"Configuration Model\"] = ConfigurationModelAnonymizer()\n",
    "\n",
    "    methods[r\"NeSt \\(d=1\\)\"] = NestModelAnonymizer(depth=1, r=10)\n",
    "    methods[r\"NeSt \\(d=2\\)\"] = NestModelAnonymizer(depth=2, r=10)\n",
    "\n",
    "    #methods[\"PrivateColor(w=1e1)\"] = PrivateColorAnonymizer(w=1e1, alpha=alpha, is_eager=True, use_optimal1d=False)\n",
    "    methods[r\"Eager \\(w=10^{-2}\\)\"] = PrivateColorAnonymizer(w=1e-2, alpha=alpha, is_eager=True, use_optimal1d=True)\n",
    "    methods[r\"Eager \\(w=10^{-3}\\)\"] = PrivateColorAnonymizer(w=1e-3, alpha=alpha, is_eager=True, use_optimal1d=True)\n",
    "    methods[r\"Eager \\(w=10^{-4}\\)\"] = PrivateColorAnonymizer(w=1e-4, alpha=alpha, is_eager=True, use_optimal1d=True)\n",
    "\n",
    "    methods[r\"16\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(16/100*G.number_of_edges()))\n",
    "    #methods[f\"{8}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(8/100*G.number_of_edges()))\n",
    "    methods[r\"4\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(4/100*G.number_of_edges()))\n",
    "    #methods[f\"{2}% Random Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(2/100*G.number_of_edges()))\n",
    "    methods[r\"1\\% Edge Add/Del\"] = RandomEdgeAddDelAnonymizer(m = int(1/100*G.number_of_edges()))\n",
    "\n",
    "    methods[r\"128-Degree Anonymity\"] = KDegreeAnonymizer(k=128)\n",
    "    methods[r\"64-Degree Anonymity\"] = KDegreeAnonymizer(k=64)\n",
    "    #methods[f\"{32}-Degree Anonymity\"] = KDegreeAnonymizer(k=32)\n",
    "    methods[r\"16-Degree Anonymity\"] = KDegreeAnonymizer(k=16)\n",
    "    #methods[f\"{8}-Degree Anonymity\"] = KDegreeAnonymizer(k=8)\n",
    "    #methods[f\"{2}-Degree Anonymity\"] = KDegreeAnonymizer(k=2)\n",
    "\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 1\\)\"] = PygmalionModelAnonymizer(eps = 1)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = 100\\)\"] = PygmalionModelAnonymizer(eps = 100)\n",
    "    methods[r\"Pygmalion \\(\\epsilon = \\infty\\)\"] = PygmalionModelAnonymizer(eps = 100_000_000)\n",
    "\n",
    "    evaluator = Evaluator(metrics, use_igraph=True)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        print(f\"Anonymizing with method {method_name}\")\n",
    "        Ga = method.anonymize(G, random_seed=seed)\n",
    "        print(f\"Evaluating method {method_name}\")\n",
    "        data[method_name] = evaluator.evaluate(G, Ga)\n",
    "\n",
    "    enron_samples_data.append(data)\n",
    "\n",
    "os.makedirs('cache', exist_ok=True)\n",
    "with open('cache/exp3_comp_enron_samples_data.pkl', 'wb') as f:\n",
    "    pickle.dump(enron_samples_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/exp3_comp_enron_samples_data.pkl', 'rb') as f:\n",
    "    enron_samples_data = pickle.load(f)\n",
    "\n",
    "print(len(enron_samples_data))\n",
    "means, rel_stds = get_statics_of_samples(enron_samples_data)\n",
    "print(get_latex_table(enron_samples_data[0]))\n",
    "print(get_latex_table(means, precision=7))\n",
    "print(get_latex_table(rel_stds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
